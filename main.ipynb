{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import config\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "from models.phobert import UIT_VFSC_Dataset as BERTDataset\n",
    "from models.phobert import collate_fn as BERTDataset_collate_fn\n",
    "from models.fasttext_lstm import UIT_VFSC_Dataset as LSTMDataset\n",
    "from models.fasttext_lstm import collate_fn as LSTMDataset_collate_fn\n",
    "# from models.fasttext_svm.utils import Word2Vec\n",
    "\n",
    "from models.phobert import PhoBertFeedForward_base, PhoBERTLSTM_base, PhoBERTModel\n",
    "from models.fasttext_lstm import FastTextLSTMModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_fn(pred1, pred2):\n",
    "    return pred1 * 0.8 + pred2 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_fn = Accuracy(num_classes=config.NUM_CLASSES, average=\"weighted\").to(config.DEVICE)\n",
    "precision_fn = Precision(num_classes=config.NUM_CLASSES, average=\"weighted\").to(config.DEVICE)\n",
    "recall_fn = Recall(num_classes=config.NUM_CLASSES, average=\"weighted\").to(config.DEVICE)\n",
    "f1_fn = F1Score(num_classes=config.NUM_CLASSES, average=\"weighted\").to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastTextLSTMModel(\n",
       "  (model): FastTextLSTM(\n",
       "    (lstm): LSTM(300, 300, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (linear): Linear(in_features=600, out_features=3, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (acc): Accuracy()\n",
       "  (f1): F1Score()\n",
       "  (precision_fn): Precision()\n",
       "  (recall_fn): Recall()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phobert_testdata = BERTDataset(config.TEST_PATH)\n",
    "phobert_testdataloader = DataLoader(dataset=phobert_testdata, batch_size=config.BATCH_SIZE,\n",
    "                                    collate_fn=BERTDataset_collate_fn, shuffle=False,num_workers=config.NUM_WORKERS)\n",
    "\n",
    "fasttext_lstm_testdata = LSTMDataset(config.TEST_PATH)\n",
    "fasttext_lstm_testdataloader = DataLoader(dataset=fasttext_lstm_testdata, batch_size=config.BATCH_SIZE,\n",
    "                                    collate_fn=LSTMDataset_collate_fn, shuffle=False,num_workers=config.NUM_WORKERS)\n",
    "\n",
    "phobert_ff_ckpt = torch.load(config.PHOBERT_FF_CKPT, map_location=config.DEVICE)\n",
    "fasttext_lstm_ckpt = torch.load(config.LSTM_CKPT, map_location=config.DEVICE)\n",
    "# phobert_lstm_ckpt = torch.load(config.PHOBERT_LSTM_CKPT, map_location=config.DEVICE)\n",
    "\n",
    "phobert_ff = PhoBertFeedForward_base(from_pretrained=False)\n",
    "# phobert_lstm = PhoBERTLSTM_base(from_pretrained=False)\n",
    "\n",
    "phobert_ff_system = PhoBERTModel(phobert_ff)\n",
    "phobert_ff_system.load_state_dict(phobert_ff_ckpt[\"state_dict\"])\n",
    "phobert_ff_system.eval()\n",
    "phobert_ff_system.to(config.DEVICE)\n",
    "\n",
    "# phobert_lstm_system = PhoBERTModel(phobert_lstm)\n",
    "# phobert_lstm_system.load_state_dict(phobert_lstm_ckpt[\"state_dict\"])\n",
    "# phobert_lstm_system.eval()\n",
    "# phobert_lstm_system.to(config.DEVICE)\n",
    "\n",
    "fasttext_lstm_system = FastTextLSTMModel()\n",
    "fasttext_lstm_system.load_state_dict(fasttext_lstm_ckpt[\"state_dict\"])\n",
    "fasttext_lstm_system.eval()\n",
    "fasttext_lstm_system.to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/198 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch_nightly/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1570: UserWarning: The operator 'aten::cumsum.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  incremental_indices = (torch.cumsum(mask, dim=1).type_as(mask) + past_key_values_length) * mask\n",
      "Working on Model 1: 100%|██████████| 198/198 [00:42<00:00,  4.62it/s]\n",
      "Working on Model 2: 100%|██████████| 198/198 [03:04<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     loop = tqdm(phobert_testdataloader)\n",
    "#     for input_ids, attn_mask, label in loop:\n",
    "#         phobert_ff_pred = phobert_ff_system(input_ids.to(config.DEVICE), attn_mask.to(config.DEVICE))\n",
    "#         phobert_lstm_pred = phobert_lstm_system(input_ids.to(config.DEVICE), attn_mask.to(config.DEVICE))\n",
    "        \n",
    "#         ensemble_pred = ensemble_fn(phobert_ff_pred, phobert_lstm_pred)\n",
    "\n",
    "#         accuracy_val = accuracy_fn(ensemble_pred, label)\n",
    "#         precision_val = precision_fn(ensemble_pred, label)\n",
    "#         recall_val = recall_fn(ensemble_pred, label)\n",
    "#         f1_val = f1_fn(ensemble_pred, label)\n",
    "\n",
    "#         acc_list.append(accuracy_val)\n",
    "#         precision_list.append(precision_val)\n",
    "#         recall_list.append(recall_val)\n",
    "#         f1_list.append(f1_val)\n",
    "\n",
    "#         loop.set_description(\"Working\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop1 = tqdm(phobert_testdataloader)\n",
    "    loop2 = tqdm(fasttext_lstm_testdataloader)\n",
    "\n",
    "    pred1 = []\n",
    "    pred2 = []\n",
    "    label1 = []\n",
    "    label2 = []\n",
    "\n",
    "    for input_ids, attn_mask, label in loop1:\n",
    "        phobert_ff_pred = phobert_ff_system(input_ids.to(config.DEVICE), attn_mask.to(config.DEVICE))\n",
    "        pred1.append(phobert_ff_pred)\n",
    "        label1.append(label)\n",
    "        loop1.set_description(\"Working on Model 1\")\n",
    "\n",
    "\n",
    "    for vec, label in loop2:\n",
    "        fasttext_lstm_pred = fasttext_lstm_system(vec.to(config.DEVICE))\n",
    "        pred2.append(fasttext_lstm_pred)\n",
    "        label2.append(label)\n",
    "        loop2.set_description(\"Working on Model 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3166, 3])\n"
     ]
    }
   ],
   "source": [
    "pred1 = torch.cat(pred1, dim=0)\n",
    "pred2 = torch.cat(pred2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3166, 3])\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = ensemble_fn(pred1, pred2)\n",
    "print(ensemble_pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = torch.cat(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAccuracy: 0.9198\u001b[0m\n",
      "\u001b[34mPrecision: 0.9131\u001b[0m\n",
      "\u001b[34mRecall: 0.9198\u001b[0m\n",
      "\u001b[34mF1-score: 0.9127\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "accuracy_val = accuracy_fn(ensemble_pred.to(config.DEVICE), label1.to(config.DEVICE))\n",
    "precision_val = precision_fn(ensemble_pred.to(config.DEVICE), label1.to(config.DEVICE))\n",
    "recall_val = recall_fn(ensemble_pred.to(config.DEVICE), label1.to(config.DEVICE))\n",
    "f1_val = f1_fn(ensemble_pred.to(config.DEVICE), label1.to(config.DEVICE))\n",
    "\n",
    "print(colored(f\"Accuracy: {accuracy_val:.4f}\", \"blue\"))        \n",
    "print(colored(f\"Precision: {precision_val:.4f}\", \"blue\"))        \n",
    "print(colored(f\"Recall: {recall_val:.4f}\", \"blue\"))        \n",
    "print(colored(f\"F1-score: {f1_val:.4f}\", \"blue\"))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch_nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2049e93406cf62fed4bf578bc8e2ee7ecd7cf5795558f7d764e33db5a2a0cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
